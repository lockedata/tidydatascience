{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting data in and out of R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into ‘/home/nbuser/R’\n",
      "(as ‘lib’ is unspecified)\n",
      "Warning message in install.packages(c(\"tidyverse\", \"readxl\", \"writexl\")):\n",
      "“installation of package ‘readxl’ had non-zero exit status”Warning message in install.packages(c(\"tidyverse\", \"readxl\", \"writexl\")):\n",
      "“installation of package ‘tidyverse’ had non-zero exit status”"
     ]
    }
   ],
   "source": [
    "install.packages(c(\"tidyverse\", \"readxl\", \"writexl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with \"nice\" data\n",
    "Usually if someone provides a CSV we're pretty thankful -- no formatting denoting data, not extra bits and pieces, just pure (hopefully) clean data to work with.\n",
    "\n",
    "If we make the `tidyverse` available to our R code, it'll give us a `read_csv()` function for loading CSVs into R. This contains a number of arguments we can use to customise the import and is faster than the base `read.csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: package or namespace load failed for ‘tidyverse’ in library.dynam(lib, package, package.lib):\n shared object ‘readxl.so’ not found\n",
     "output_type": "error",
     "traceback": [
      "Error: package or namespace load failed for ‘tidyverse’ in library.dynam(lib, package, package.lib):\n shared object ‘readxl.so’ not found\nTraceback:\n",
      "1. library(tidyverse)",
      "2. tryCatch({\n .     attr(package, \"LibPath\") <- which.lib.loc\n .     ns <- loadNamespace(package, lib.loc)\n .     env <- attachNamespace(ns, pos = pos, deps)\n . }, error = function(e) {\n .     P <- if (!is.null(cc <- conditionCall(e))) \n .         paste(\" in\", deparse(cc)[1L])\n .     else \"\"\n .     msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", \n .         sQuote(package), P, conditionMessage(e))\n .     if (logical.return) \n .         message(paste(\"Error:\", msg), domain = NA)\n .     else stop(msg, call. = FALSE, domain = NA)\n . })",
      "3. tryCatchList(expr, classes, parentenv, handlers)",
      "4. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "5. value[[3L]](cond)",
      "6. stop(msg, call. = FALSE, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "heroes <- read_csv(\"data/heroes_information.csv\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're able to do all sorts of snazzy things with this `read_csv()` function like making suring the data types are what we expect, adding nice new headers, handling weird values for missing data and more. Very handily, when we first run a `read_csv()` command it tells us what the column names and data types will be as a *message* in the console. These sorts of things can show up in red text and look pretty scary but this in particular is just a heads up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Can you write a revised `read_csv()` that improves the column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your read_csv() code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Excel data\n",
    "Assuming the data isn't too yucky, the `readxl` package is super easy to use. It uses a function very similar `read_csv()`, and that's `read_excel()`. Learning one makes it easy to learn the other. As well as using it simply where it works on the default tab, you can specifiy sheets, ranges and all sort of stuff to extract data. Here I'm going to use the `skip` to avoid any problems reading the title and stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readxl)\n",
    "heroes = read_excel(\"data/heroes_information.xlsx\", skip = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone left a filter on the Excel spreadsheet. Let's see if that filter was maintained when we loaded the data. I can see it was on the `Alignment` column so we should see if we can get a list of unique values present in that column in our `heroes` dataset. We can tell R to we're talking about a specific column by using the format `[tablename]$[Column]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(heroes$Alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew, it found all the values so our spreadsheet reads are safe from pesky filters! Let's look at our data a bit more, using the `summary()` function as a quick start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(heroes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Huh, we have NA (missing) and -99 for missings! Typical. Can you use the `na` argument to the `read_excel()` command to include -99 as a missing value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other data sources\n",
    "R is amazing at talking to so many things! We can work with Google Sheets, databases, APIs, web scraping, and even pry data from the horrible PDFs some people insist counts as \"publishing data\". Here are some links for next steps when it comes time to work different sources:\n",
    "\n",
    "- [googlesheets docs](https://github.com/jennybc/googlesheets/blob/master/vignettes/basic-usage.md)\n",
    "- [a great webscraping demo](https://masalmon.eu/2018/06/18/mathtree/)\n",
    "- [a nifty pdf scraping demo](http://www.brodrigues.co/blog/2018-06-10-scraping_pdfs/)\n",
    "- [consuming airtable demo](https://itsalocke.com/blog/how-to-use-an-r-interface-with-airtable-api/)\n",
    "- [working with databases](https://db.rstudio.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data to CSV\n",
    "The `write_csv()` function from the `readr` package which we loaded when we ran `library(tidyverse)`. Like the `read_csv()` function it has some optional arguments you can use to tweak the export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir.create(\"outputs\", showWarnings = FALSE) # this stops it from making red text if the directory already exists\n",
    "write_csv(heroes, \"outputs/heroes_information.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data to Excel\n",
    "We've installed the `writexl` package to do simple exports to Excel. \n",
    "\n",
    "If you want more control over look and feel, checkout the `openxlsx` package. If that isn't good enough you probably need the `XLConnect` package. This uses Java and makes kittens cry so pretty please, try to do things another way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(writexl)\n",
    "write_xlsx(heroes, \"outputs/heroes_information.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
